<!DOCTYPE html>
<meta charset="utf-8">
<title>Image-based rendering for Kleinian groups</title>

<style>
    body { font-family: sans-serif; }
    canvas { display: block; margin: auto; width: 1024px; height: 1024px; border: 10px solid #000; }
    #fail { color: red; white-space: pre-wrap; max-width: 600px; }
</style>

<script type="x-webgl/x-vertex-shader" id="vertex-shader">
attribute vec2 a_position;

void main() {
    gl_Position = vec4(a_position, 0, 1);
}
</script>

<script type="x-webgl/x-fragment-shader" id="timestep-shader">
precision mediump float;
uniform sampler2D u_image;
uniform vec2 u_size;

// The world space coordinates of our image are (-4,-4) to (4,4)
const vec2 world_size = vec2(8,8);
const vec2 world_offset = vec2(-4,-4);

float len2( vec2 a )
{
    return a.x * a.x + a.y * a.y;
}

vec2 mul_complex( vec2 a, vec2 b )
{
    return vec2( a.x * b.x - a.y * b.y, a.y * b.x + a.x * b.y );
}

vec2 div_complex( vec2 a, vec2 b )
{
    return vec2( ( a.x * b.x + a.y * b.y ) / len2( b ), ( a.y * b.x - a.x * b.y ) / len2( b ) );
}

vec2 mobius_on_point( vec2 a, vec2 b, vec2 c, vec2 d, vec2 z )
{
    // apply the Mobius transform m to the point z

    /*if( isnan(z[0]) || isnan(z[1]) ) {
        // special case for z = inf, return a / c
        return div_complex( a, c );
    }*/
    return div_complex( mul_complex( a, z ) + b, mul_complex( c, z ) + d );
}

void main() {
    // Parameters from Grandma's four alarm special from Indra's Pearls, p. 260. With ta = 1.870000 + 0.080000i, tb = 1.870000 - 0.100000i, tab = 1.790000 - 1.948000i
    // https://timhutton.github.io/mobius-transforms/dfs_recipes.html?id=special&ta.x=1.870000&ta.y=0.080000&tb.x=1.870000&tb.y=-0.100000&tab.x=1.790000&tab.y=-1.948000
    vec2 m[16];  // Four Mobius transforms, each is four complex numbers
    m[0] = vec2(0.935,0.04);
    m[1] = vec2(-0.05842334444968401,-0.07144275973942649);
    m[2] = vec2(0.2462918414410266,-1.5814871559334707);
    m[3] = vec2(0.935,0.04);
    m[4] = vec2(0.9547285139975278,-1.0266878540580662);
    m[5] = vec2(1.1661281224631066,-0.13336761357578011);
    m[6] = vec2(0.7038718775368936,0.03336761357578018);
    m[7] = vec2(0.9152714860024723,0.9266878540580662);
    m[8] = vec2(0.935,0.04);
    m[9] = vec2(0.05842334444968401,0.07144275973942649);
    m[10] = vec2(-0.2462918414410266,1.5814871559334707);
    m[11] = vec2(0.935,0.04);
    m[12] = vec2(0.9152714860024723,0.9266878540580662);
    m[13] = vec2(-1.1661281224631066,0.13336761357578011);
    m[14] = vec2(-0.7038718775368936,-0.03336761357578018);
    m[15] = vec2(0.9547285139975278,-1.0266878540580662);

    // subsample the pixel NxN
    const int N = 3;
    vec4 col = vec4(0,0,0,1);
    for(int i=0;i<N;i++)
    {
        for(int j=0;j<N;j++)
        {
            vec2 pixel_xy = gl_FragCoord.xy - vec2(0.5, 0.5) + vec2(i,j) / float(N-1);
            // map pixel coords to [0,1]
            vec2 uv = pixel_xy / u_size;
            // map [0,1] to world space
            vec2 p = uv * world_size + world_offset;
            // find the source points for this pixel
            vec2 p0 = mobius_on_point(m[0], m[1], m[2], m[3], p);
            vec2 p1 = mobius_on_point(m[4], m[5], m[6], m[7], p);
            vec2 p2 = mobius_on_point(m[8], m[9], m[10], m[11], p);
            vec2 p3 = mobius_on_point(m[12], m[13], m[14], m[15], p);
            // map world space to [0,1]
            vec2 uv0 = ( p0 - world_offset ) / world_size;
            vec2 uv1 = ( p1 - world_offset ) / world_size;
            vec2 uv2 = ( p2 - world_offset ) / world_size;
            vec2 uv3 = ( p3 - world_offset ) / world_size;
            // sample the texture at those points, if on-screen
            if(uv0.x >= 0.0 && uv0.x <= 1.0 && uv0.y >= 0.0 && uv0.y <= 1.0) col += texture2D(u_image, uv0);
            if(uv1.x >= 0.0 && uv1.x <= 1.0 && uv1.y >= 0.0 && uv1.y <= 1.0) col += texture2D(u_image, uv1);
            if(uv2.x >= 0.0 && uv2.x <= 1.0 && uv2.y >= 0.0 && uv2.y <= 1.0) col += texture2D(u_image, uv2);
            if(uv3.x >= 0.0 && uv3.x <= 1.0 && uv3.y >= 0.0 && uv3.y <= 1.0) col += texture2D(u_image, uv3);
        }
    }

    // assign the mean of all of those samples back to our pixel
    gl_FragColor = vec4( col.xyz / float( 4 * N * N ), 1);
}
</script>

<script type="x-webgl/x-fragment-shader" id="render-shader">
precision mediump float;
uniform sampler2D u_image;
uniform vec2 u_size;

void main() {
    gl_FragColor = texture2D(u_image, gl_FragCoord.xy / u_size);
}
</script>

<body>
<script>
var W = 1024, H = 1024;

function init() {
    if (window.parent && window.parent != window) {
        var iframe = window.parent.document.querySelector("iframe");
        iframe.style.width = "1044px";
        iframe.style.height = "532px";
    }

    var canvas = document.createElement("canvas");

    canvas.id = "canvas";
    canvas.width = W;
    canvas.height = H;
    document.body.appendChild(canvas);

    var gl = canvas.getContext("webgl") || canvas.getContext("experimental-webgl");
    checkCompatibility(gl);

    var vertex_shader = createShader(gl, gl.VERTEX_SHADER, "vertex-shader"),
        timestep_shader = createShader(gl, gl.FRAGMENT_SHADER, "timestep-shader"),
        render_shader = createShader(gl, gl.FRAGMENT_SHADER, "render-shader");

    var timestep_prog = createAndLinkProgram(gl, vertex_shader, timestep_shader),
        render_prog = createAndLinkProgram(gl, vertex_shader, render_shader);

    gl.useProgram(render_prog);
    loadVertexData(gl, render_prog);
    gl.uniform2f(gl.getUniformLocation(render_prog, "u_size"), W, H);

    gl.useProgram(timestep_prog);
    loadVertexData(gl, timestep_prog);
    gl.uniform2f(gl.getUniformLocation(timestep_prog, "u_size"), W, H);

    var initial_state = getInitialState();
    var t1 = newTexture(gl, initial_state),
        t2 = newTexture(gl, null),
        fb1 = newFramebuffer(gl, t1),
        fb2 = newFramebuffer(gl, t2);

    // Check the hardware can render to a float framebuffer
    // (https://developer.mozilla.org/en-US/docs/Web/WebGL/WebGL_best_practices)
    gl.useProgram(timestep_prog);
    gl.bindFramebuffer(gl.FRAMEBUFFER, fb1);
    var fb_status = gl.checkFramebufferStatus(gl.FRAMEBUFFER);
    if (fb_status != gl.FRAMEBUFFER_COMPLETE) {
        fail("Cannot render to framebuffer: " + fb_status);
    }

    function step() {
        gl.useProgram(timestep_prog);
        for (var i=0; i<20; i++) {
            gl.bindTexture(gl.TEXTURE_2D, [t1, t2][i % 2]);
            gl.bindFramebuffer(gl.FRAMEBUFFER, [fb2, fb1][i % 2]);
            gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
        }

        gl.useProgram(render_prog);
        gl.bindTexture(gl.TEXTURE_2D, t1);
        gl.bindFramebuffer(gl.FRAMEBUFFER, null);
        gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
    }

    var af;
    function frame() {
        step();
        af = requestAnimationFrame(frame);
    }
    af = requestAnimationFrame(frame);
}

function getInitialState() {
    var a = new Float32Array(4 * W * H);

    for (var y=0; y<H; y++) {
        for (var x=0; x<W; x++) {
            var i = W*y + x;
            a[4*i + 0] = 1;
            a[4*i + 1] = 1;
            a[4*i + 2] = 1;
            a[4*i + 3] = 1;
        }
    }

    return a;
}

// Create, initialise, and bind a new texture
function newTexture(gl, initial_state) {
    var texture = gl.createTexture();
    gl.bindTexture(gl.TEXTURE_2D, texture);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
    gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, W, H, 0, gl.RGBA, gl.FLOAT, initial_state);

    return texture;
}

function newFramebuffer(gl, texture) {
    var fb = gl.createFramebuffer();
    gl.bindFramebuffer(gl.FRAMEBUFFER, fb);
    gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0);

    return fb;
}

function loadVertexData(gl, prog) {
    gl.bindBuffer(gl.ARRAY_BUFFER, gl.createBuffer());
    gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([ -1,-1, 1,-1, -1,1, 1,1 ]), gl.STATIC_DRAW);

    var a_position = gl.getAttribLocation(prog, "a_position");
    gl.enableVertexAttribArray(a_position);
    gl.vertexAttribPointer(a_position, 2, gl.FLOAT, false, 0, 0);
}

function createAndLinkProgram(gl, vertex_shader, fragment_shader) {
    var prog = gl.createProgram();
    gl.attachShader(prog, vertex_shader);
    gl.attachShader(prog, fragment_shader);
    gl.linkProgram(prog);
    if (!gl.getProgramParameter(prog, gl.LINK_STATUS)) {
        fail("Failed to link program: " + gl.getProgramInfoLog(prog));
    }
    return prog;
}

function createShader(gl, shader_type, shader_code_id) {
    var shader = gl.createShader(shader_type);
    gl.shaderSource(shader, document.getElementById(shader_code_id).text);
    gl.compileShader(shader);
    if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
        var err = gl.getShaderInfoLog(shader);
        fail("Failed to compile shader: " + err);
    }
    return shader
}

function checkCompatibility(gl) {
    if (!gl) fail("WebGL is not supported");

    var float_texture_ext = gl.getExtension("OES_texture_float");
    if (!float_texture_ext) fail("Your browser does not support the WebGL extension OES_texture_float");
    window.float_texture_ext = float_texture_ext; // Hold onto it

    var max_texture_size = gl.getParameter(gl.MAX_TEXTURE_SIZE);
    if (max_texture_size < 512) fail("Your browser only supports "+max_texture_size+"×"+max_texture_size+" WebGL textures");
}

function fail(message) {
    var fail = document.createElement("p");
    fail.id = "fail";
    fail.appendChild(document.createTextNode(message));
    document.body.removeChild(document.getElementById("canvas"));
    document.body.appendChild(fail);
    throw message;
}

init();
</script>
</body>
